             +++++ NCN Postgres Health Checks +++++
=== Can Be Executed on any ncn worker or master node. ===
=== Executing on ncn-m001, Thu Nov  7 10:10:03 UTC 2024 ===

=== Postgresql Operator Version ===
artifactory.algol60.net/csm-docker/stable/registry.opensource.zalan.do/acid/postgres-operator:v1.8.2

=== List of Postgresql Clusters Using Operator ===
NAMESPACE   NAME                         TEAM                VERSION   PODS   VOLUME   CPU-REQUEST   MEMORY-REQUEST   AGE   STATUS
argo        cray-nls-postgres            cray-nls            14        3      2Gi                                     13d   Running
services    cfs-ara-postgres             cfs-ara             14        3      50Gi                                    13d   Running
services    cray-console-data-postgres   cray-console-data   14        3      2Gi                                     13d   Running
services    cray-dhcp-kea-postgres       cray-dhcp-kea       14        3      10Gi     2             1Gi              13d   Running
services    cray-dns-powerdns-postgres   cray-dns-powerdns   14        3      10Gi                                    13d   Running
services    cray-sls-postgres            cray-sls            14        3      1Gi                                     13d   Running
services    cray-smd-postgres            cray-smd            14        3      100Gi    4             8Gi              13d   Running
services    gitea-vcs-postgres           gitea-vcs           14        3      50Gi                                    12d   Running
services    keycloak-postgres            keycloak            14        3      10Gi                                    13d   Running
spire       cray-spire-postgres          cray-spire          14        3      60Gi     4             4Gi              12d   Running
spire       spire-postgres               spire               14        3      60Gi     4             4Gi              12d   Running

=== Look at patronictl list info for each cluster, determine and attach to leader of each cluster ===
=== Report status of postgres pods in cluster ===
-----------------------------------------------------------------------------------------------------

=== Looking at patronictl list info for the cray-nls-postgres cluster with leader pod: cray-nls-postgres-0 ===

--- patronictl, version , list for argo leader pod cray-nls-postgres-0 ---
+ Cluster: cray-nls-postgres (7429648723677089861) ----+----+-----------+
| Member              | Host       | Role    | State   | TL | Lag in MB |
+---------------------+------------+---------+---------+----+-----------+
| cray-nls-postgres-0 | 10.36.0.17 | Leader  | running |  6 |           |
| cray-nls-postgres-1 | 10.34.0.44 | Replica | running |  6 |         0 |
| cray-nls-postgres-2 | 10.41.0.75 | Replica | running |  6 |         0 |
+---------------------+------------+---------+---------+----+-----------+
NAMESPACE            NAME                                                              READY   STATUS            RESTARTS         AGE     IP            NODE       NOMINATED NODE   READINESS GATES
argo                 cray-nls-postgres-0                                               3/3     Running       0                2d3h    10.36.0.17    ncn-w001   <none>           <none>
argo                 cray-nls-postgres-1                                               3/3     Running       0                21h     10.34.0.44    ncn-w002   <none>           <none>
argo                 cray-nls-postgres-2                                               3/3     Running       0                4d12h   10.41.0.75    ncn-w004   <none>           <none>

--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------

=== Looking at patronictl list info for the cfs-ara-postgres cluster with leader pod: cfs-ara-postgres-0 ===

--- patronictl, version , list for services leader pod cfs-ara-postgres-0 ---
+ Cluster: cfs-ara-postgres (7429653337307897930) ----+----+-----------+
| Member             | Host       | Role    | State   | TL | Lag in MB |
+--------------------+------------+---------+---------+----+-----------+
| cfs-ara-postgres-0 | 10.41.0.70 | Leader  | running |  5 |           |
| cfs-ara-postgres-1 | 10.44.0.19 | Replica | running |  5 |         0 |
| cfs-ara-postgres-2 | 10.36.0.73 | Replica | running |  5 |         0 |
+--------------------+------------+---------+---------+----+-----------+
NAMESPACE            NAME                                                              READY   STATUS        RESTARTS         AGE     IP            NODE       NOMINATED NODE   READINESS GATES
services             cfs-ara-postgres-0                                                3/3     Running       0                4d12h   10.41.0.70    ncn-w004   <none>           <none>
services             cfs-ara-postgres-1                                                3/3     Terminating   0                4d12h   10.44.0.19    ncn-w003   <none>           <none>
services             cfs-ara-postgres-2                                                3/3     Running       0                21h     10.36.0.73    ncn-w001   <none>           <none>
--- ERROR --- not all cfs-ara-postgres pods have status 'Running'

--- Error Logs for services "Leader Pod" cfs-ara-postgres-0 --- 
2024-11-06 17:46:51,807 ERROR: Request to server https://10.16.0.1:443 failed: ReadTimeoutError("HTTPSConnectionPool(host='10.16.0.1', port=443): Read timed out. (read timeout=4.999599705042783)",)
2024-11-07 05:10:41,810 ERROR: Request to server https://10.16.0.1:443 failed: ReadTimeoutError("HTTPSConnectionPool(host='10.16.0.1', port=443): Read timed out. (read timeout=4.999635601998307)",)
ERROR:  extension "pg_cron" does not exist
ERROR:  extension "pg_cron" must be installed in schema "pg_catalog"
ERROR:  schema "cron" does not exist

--- Error Logs for services non-leader pod cfs-ara-postgres-1 --- 

--- Error Logs for services non-leader pod cfs-ara-postgres-2 --- 

 * The logs above show up to 50 of the most recent errors * 

--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------

=== Looking at patronictl list info for the cray-console-data-postgres cluster with leader pod: cray-console-data-postgres-0 ===

--- patronictl, version , list for services leader pod cray-console-data-postgres-0 ---
+ Cluster: cray-console-data-postgres (7429653366548672586) ----+----+-----------+
| Member                       | Host       | Role    | State   | TL | Lag in MB |
+------------------------------+------------+---------+---------+----+-----------+
| cray-console-data-postgres-0 | 10.41.0.37 | Leader  | running |  3 |           |
| cray-console-data-postgres-1 | 10.34.0.49 | Replica | running |  3 |         0 |
| cray-console-data-postgres-2 | 10.36.0.19 | Replica | running |  3 |         0 |
+------------------------------+------------+---------+---------+----+-----------+
NAMESPACE            NAME                                                              READY   STATUS        RESTARTS         AGE     IP            NODE       NOMINATED NODE   READINESS GATES
services             cray-console-data-postgres-0                                      3/3     Running       0                4d13h   10.41.0.37    ncn-w004   <none>           <none>
services             cray-console-data-postgres-1                                      3/3     Running       0                21h     10.34.0.49    ncn-w002   <none>           <none>
services             cray-console-data-postgres-2                                      3/3     Running       0                2d3h    10.36.0.19    ncn-w001   <none>           <none>

--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------

=== Looking at patronictl list info for the cray-dhcp-kea-postgres cluster with leader pod: cray-dhcp-kea-postgres-1 ===

--- patronictl, version , list for services leader pod cray-dhcp-kea-postgres-1 ---
+ Cluster: cray-dhcp-kea-postgres (7429648994707337289) ----+----+-----------+
| Member                   | Host       | Role    | State   | TL | Lag in MB |
+--------------------------+------------+---------+---------+----+-----------+
| cray-dhcp-kea-postgres-0 | 10.34.0.48 | Replica | running |  5 |         0 |
| cray-dhcp-kea-postgres-1 | 10.41.0.72 | Leader  | running |  5 |           |
| cray-dhcp-kea-postgres-2 | 10.36.0.30 | Replica | running |  5 |         0 |
+--------------------------+------------+---------+---------+----+-----------+
NAMESPACE            NAME                                                              READY   STATUS        RESTARTS         AGE     IP            NODE       NOMINATED NODE   READINESS GATES
services             cray-dhcp-kea-postgres-0                                          3/3     Running       0                21h     10.34.0.48    ncn-w002   <none>           <none>
services             cray-dhcp-kea-postgres-1                                          3/3     Running       0                4d12h   10.41.0.72    ncn-w004   <none>           <none>
services             cray-dhcp-kea-postgres-2                                          3/3     Running       0                47h     10.36.0.30    ncn-w001   <none>           <none>

--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------

=== Looking at patronictl list info for the cray-dns-powerdns-postgres cluster with leader pod: cray-dns-powerdns-postgres-0 ===

--- patronictl, version , list for services leader pod cray-dns-powerdns-postgres-0 ---
+ Cluster: cray-dns-powerdns-postgres (7429649497407156297) ----+----+-----------+
| Member                       | Host       | Role    | State   | TL | Lag in MB |
+------------------------------+------------+---------+---------+----+-----------+
| cray-dns-powerdns-postgres-0 | 10.41.0.22 | Leader  | running |  3 |           |
| cray-dns-powerdns-postgres-1 | 10.36.0.28 | Replica | running |  3 |         0 |
| cray-dns-powerdns-postgres-2 | 10.44.0.68 | Replica | running |  3 |         0 |
+------------------------------+------------+---------+---------+----+-----------+
NAMESPACE            NAME                                                              READY   STATUS        RESTARTS         AGE     IP            NODE       NOMINATED NODE   READINESS GATES
services             cray-dns-powerdns-postgres-0                                      3/3     Running       0                4d13h   10.41.0.22    ncn-w004   <none>           <none>
services             cray-dns-powerdns-postgres-1                                      3/3     Running       0                21h     10.36.0.28    ncn-w001   <none>           <none>
services             cray-dns-powerdns-postgres-2                                      3/3     Terminating   0                4d12h   10.44.0.68    ncn-w003   <none>           <none>
--- ERROR --- not all cray-dns-powerdns-postgres pods have status 'Running'

--- Error Logs for services "Leader Pod" cray-dns-powerdns-postgres-0 --- 
2024-11-02 20:18:46,673 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError('HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ReadTimeoutError("HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Read timed out. (read timeout=2.5)",))',)
2024-11-02 21:31:08,444 ERROR: Request to server https://10.16.0.1:443 failed: ReadTimeoutError("HTTPSConnectionPool(host='10.16.0.1', port=443): Read timed out. (read timeout=2.5)",)
2024-11-02 21:31:10,676 ERROR: Request to server https://10.16.0.1:443 failed: ReadTimeoutError("HTTPSConnectionPool(host='10.16.0.1', port=443): Read timed out. (read timeout=1.7563079595565796)",)
2024-11-02 21:31:13,668 ERROR: Request to server https://10.16.0.1:443 failed: ReadTimeoutError("HTTPSConnectionPool(host='10.16.0.1', port=443): Read timed out. (read timeout=2.2324654164985986)",)
2024-11-02 21:31:15,262 ERROR: Request to server https://10.16.0.1:443 failed: ReadTimeoutError("HTTPSConnectionPool(host='10.16.0.1', port=443): Read timed out. (read timeout=1)",)
2024-11-02 21:31:18,445 ERROR: Request to server https://10.16.0.1:443 failed: ReadTimeoutError("HTTPSConnectionPool(host='10.16.0.1', port=443): Read timed out. (read timeout=2.5)",)
ERROR:  extension "pg_cron" does not exist
ERROR:  extension "pg_cron" must be installed in schema "pg_catalog"
ERROR:  schema "cron" does not exist

--- Error Logs for services non-leader pod cray-dns-powerdns-postgres-1 --- 

--- Error Logs for services non-leader pod cray-dns-powerdns-postgres-2 --- 

 * The logs above show up to 50 of the most recent errors * 

--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------

=== Looking at patronictl list info for the cray-sls-postgres cluster with leader pod: cray-sls-postgres-0 ===

--- patronictl, version , list for services leader pod cray-sls-postgres-0 ---
+ Cluster: cray-sls-postgres (7429648913392148553) ----+----+-----------+
| Member              | Host       | Role    | State   | TL | Lag in MB |
+---------------------+------------+---------+---------+----+-----------+
| cray-sls-postgres-0 | 10.41.0.71 | Leader  | running |  6 |           |
| cray-sls-postgres-1 | 10.36.0.72 | Replica | running |  6 |         0 |
| cray-sls-postgres-2 | 10.44.0.67 | Replica | running |  6 |         0 |
+---------------------+------------+---------+---------+----+-----------+
NAMESPACE            NAME                                                              READY   STATUS        RESTARTS         AGE     IP            NODE       NOMINATED NODE   READINESS GATES
services             cray-sls-postgres-0                                               3/3     Running       0                4d12h   10.41.0.71    ncn-w004   <none>           <none>
services             cray-sls-postgres-1                                               3/3     Running       0                21h     10.36.0.72    ncn-w001   <none>           <none>
services             cray-sls-postgres-2                                               3/3     Terminating   0                4d12h   10.44.0.67    ncn-w003   <none>           <none>
--- ERROR --- not all cray-sls-postgres pods have status 'Running'

--- Error Logs for services "Leader Pod" cray-sls-postgres-0 --- 
2024-11-06 17:46:55,994 ERROR: Request to server https://10.16.0.1:443 failed: ReadTimeoutError("HTTPSConnectionPool(host='10.16.0.1', port=443): Read timed out. (read timeout=4.999749192968011)",)
2024-11-06 17:46:57,457 ERROR: Request to server https://10.16.0.1:443 failed: ReadTimeoutError("HTTPSConnectionPool(host='10.16.0.1', port=443): Read timed out. (read timeout=1.178333818912506)",)
2024-11-06 17:46:58,961 ERROR: Request to server https://10.16.0.1:443 failed: ReadTimeoutError("HTTPSConnectionPool(host='10.16.0.1', port=443): Read timed out. (read timeout=1)",)
2024-11-06 17:46:58,961 ERROR: failed to update leader lock
2024-11-07 05:10:47,565 ERROR: Request to server https://10.16.0.1:443 failed: ReadTimeoutError("HTTPSConnectionPool(host='10.16.0.1', port=443): Read timed out. (read timeout=4.9996684530051425)",)
2024-11-07 05:10:50,369 ERROR: Request to server https://10.16.0.1:443 failed: ReadTimeoutError("HTTPSConnectionPool(host='10.16.0.1', port=443): Read timed out. (read timeout=2.1902265818207525)",)
ERROR:  extension "pg_cron" does not exist
ERROR:  extension "pg_cron" must be installed in schema "pg_catalog"
ERROR:  schema "cron" does not exist

--- Error Logs for services non-leader pod cray-sls-postgres-1 --- 

--- Error Logs for services non-leader pod cray-sls-postgres-2 --- 

 * The logs above show up to 50 of the most recent errors * 

--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------

=== Looking at patronictl list info for the cray-smd-postgres cluster with leader pod: cray-smd-postgres-2 ===

--- patronictl, version , list for services leader pod cray-smd-postgres-2 ---
+ Cluster: cray-smd-postgres (7429648967686664265) ----+----+-----------+
| Member              | Host       | Role    | State   | TL | Lag in MB |
+---------------------+------------+---------+---------+----+-----------+
| cray-smd-postgres-0 | 10.34.0.47 | Replica | running |  4 |         0 |
| cray-smd-postgres-1 | 10.36.0.23 | Replica | running |  4 |         0 |
| cray-smd-postgres-2 | 10.41.0.73 | Leader  | running |  4 |           |
+---------------------+------------+---------+---------+----+-----------+
NAMESPACE            NAME                                                              READY   STATUS        RESTARTS         AGE     IP            NODE       NOMINATED NODE   READINESS GATES
services             cray-smd-postgres-0                                               3/3     Running       0               21h     10.34.0.47    ncn-w002   <none>           <none>
services             cray-smd-postgres-1                                               3/3     Running       0               2d3h    10.36.0.23    ncn-w001   <none>           <none>
services             cray-smd-postgres-2                                               3/3     Running       0               4d13h   10.41.0.73    ncn-w004   <none>           <none>

--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------

=== Looking at patronictl list info for the gitea-vcs-postgres cluster with leader pod: gitea-vcs-postgres-0 ===

--- patronictl, version , list for services leader pod gitea-vcs-postgres-0 ---
+ Cluster: gitea-vcs-postgres (7429653957876965450) ----+----+-----------+
| Member               | Host       | Role    | State   | TL | Lag in MB |
+----------------------+------------+---------+---------+----+-----------+
| gitea-vcs-postgres-0 | 10.41.0.69 | Leader  | running |  4 |           |
| gitea-vcs-postgres-1 | 10.36.0.14 | Replica | running |  4 |         0 |
| gitea-vcs-postgres-2 | 10.44.0.70 | Replica | running |  4 |        16 |
+----------------------+------------+---------+---------+----+-----------+
--- WARNING --- gitea-vcs-postgres members have Lag

NAMESPACE            NAME                                                              READY   STATUS        RESTARTS        AGE     IP            NODE       NOMINATED NODE   READINESS GATES
services             gitea-vcs-postgres-0                                              3/3     Running       0               4d12h   10.41.0.69    ncn-w004   <none>           <none>
services             gitea-vcs-postgres-1                                              3/3     Running       0               2d3h    10.36.0.14    ncn-w001   <none>           <none>
services             gitea-vcs-postgres-2                                              3/3     Terminating   0               21h     10.44.0.70    ncn-w003   <none>           <none>
--- ERROR --- not all gitea-vcs-postgres pods have status 'Running'

--- Error Logs for services "Leader Pod" gitea-vcs-postgres-0 --- 
ERROR:  extension "pg_cron" does not exist
ERROR:  extension "pg_cron" must be installed in schema "pg_catalog"
ERROR:  schema "cron" does not exist

--- Error Logs for services non-leader pod gitea-vcs-postgres-1 --- 

--- Error Logs for services non-leader pod gitea-vcs-postgres-2 --- 

 * The logs above show up to 50 of the most recent errors * 

--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------

=== Looking at patronictl list info for the keycloak-postgres cluster with leader pod: keycloak-postgres-2 ===

--- patronictl, version , list for services leader pod keycloak-postgres-2 ---
+ Cluster: keycloak-postgres (7429648627273879625) ----+----+-----------+
| Member              | Host       | Role    | State   | TL | Lag in MB |
+---------------------+------------+---------+---------+----+-----------+
| keycloak-postgres-0 | 10.44.0.69 | Replica | running |  4 |         0 |
| keycloak-postgres-1 | 10.36.0.18 | Replica | running |  4 |         0 |
| keycloak-postgres-2 | 10.41.0.74 | Leader  | running |  4 |           |
+---------------------+------------+---------+---------+----+-----------+
NAMESPACE            NAME                                                              READY   STATUS        RESTARTS        AGE     IP            NODE       NOMINATED NODE   READINESS GATES
services             keycloak-postgres-0                                               3/3     Terminating   0               21h     10.44.0.69    ncn-w003   <none>           <none>
services             keycloak-postgres-1                                               3/3     Running       0               2d3h    10.36.0.18    ncn-w001   <none>           <none>
services             keycloak-postgres-2                                               3/3     Running       0               4d13h   10.41.0.74    ncn-w004   <none>           <none>
--- ERROR --- not all keycloak-postgres pods have status 'Running'

--- Error Logs for services "Leader Pod" keycloak-postgres-2 --- 
2024-11-02 21:31:11,914 ERROR: Request to server https://10.16.0.1:443 failed: ReadTimeoutError("HTTPSConnectionPool(host='10.16.0.1', port=443): Read timed out. (read timeout=4.991518883998651)",)
2024-11-02 21:31:14,806 ERROR: Request to server https://10.16.0.1:443 failed: ReadTimeoutError("HTTPSConnectionPool(host='10.16.0.1', port=443): Read timed out. (read timeout=2.0988496715744986)",)
2024-11-02 21:31:16,913 ERROR: Request to server https://10.16.0.1:443 failed: ReadTimeoutError("HTTPSConnectionPool(host='10.16.0.1', port=443): Read timed out. (read timeout=1.514608827083066)",)
2024-11-02 21:46:07,261 ERROR: Request to server https://10.16.0.1:443 failed: ReadTimeoutError("HTTPSConnectionPool(host='10.16.0.1', port=443): Read timed out. (read timeout=4.99974613699851)",)
2024-11-02 21:46:08,643 ERROR: Request to server https://10.16.0.1:443 failed: ReadTimeoutError("HTTPSConnectionPool(host='10.16.0.1', port=443): Read timed out. (read timeout=1.2065972089767456)",)
2024-11-02 21:46:09,956 ERROR: Request to server https://10.16.0.1:443 failed: ReadTimeoutError("HTTPSConnectionPool(host='10.16.0.1', port=443): Read timed out. (read timeout=1)",)
2024-11-02 21:46:11,881 ERROR: Request to server https://10.16.0.1:443 failed: ReadTimeoutError("HTTPSConnectionPool(host='10.16.0.1', port=443): Read timed out. (read timeout=1)",)
2024-11-02 21:46:11,881 ERROR: failed to update leader lock
2024-11-02 21:46:16,979 ERROR: Request to server https://10.16.0.1:443 failed: ReadTimeoutError("HTTPSConnectionPool(host='10.16.0.1', port=443): Read timed out. (read timeout=2.5)",)
2024-11-02 21:46:19,238 ERROR: Request to server https://10.16.0.1:443 failed: ReadTimeoutError("HTTPSConnectionPool(host='10.16.0.1', port=443): Read timed out. (read timeout=1.7447105646133423)",)
2024-11-07 05:10:47,086 ERROR: Request to server https://10.16.0.1:443 failed: ReadTimeoutError("HTTPSConnectionPool(host='10.16.0.1', port=443): Read timed out. (read timeout=4.9996810060110874)",)
ERROR:  extension "pg_cron" does not exist
ERROR:  extension "pg_cron" must be installed in schema "pg_catalog"
ERROR:  schema "cron" does not exist

--- Error Logs for services non-leader pod keycloak-postgres-0 --- 

--- Error Logs for services non-leader pod keycloak-postgres-1 --- 
2024-11-05 06:59:46,034 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-05 06:59:46,036 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-05 06:59:49,017 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError('HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ReadTimeoutError("HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Read timed out. (read timeout=2.5)",))',)
2024-11-05 06:59:50,018 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-05 06:59:51,046 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError('HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ReadTimeoutError("HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Read timed out. (read timeout=2.5)",))',)
2024-11-05 06:59:52,048 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-05 06:59:52,523 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: ClosedPoolError("HTTPSConnectionPool(host='10.16.0.1', port=443): Pool is closed.",)
2024-11-05 06:59:53,524 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-05 06:59:54,553 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: ClosedPoolError("HTTPSConnectionPool(host='10.16.0.1', port=443): Pool is closed.",)
2024-11-05 06:59:55,554 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-05 06:59:56,029 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: ClosedPoolError("HTTPSConnectionPool(host='10.16.0.1', port=443): Pool is closed.",)
2024-11-05 06:59:57,030 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-05 06:59:58,059 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: ClosedPoolError("HTTPSConnectionPool(host='10.16.0.1', port=443): Pool is closed.",)
2024-11-05 06:59:59,060 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-05 06:59:59,535 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: ClosedPoolError("HTTPSConnectionPool(host='10.16.0.1', port=443): Pool is closed.",)
2024-11-05 07:00:00,023 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: ClosedPoolError("HTTPSConnectionPool(host='10.16.0.1', port=443): Pool is closed.",)
2024-11-05 07:00:00,536 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-05 07:00:01,566 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: ClosedPoolError("HTTPSConnectionPool(host='10.16.0.1', port=443): Pool is closed.",)
2024-11-05 07:00:02,566 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-05 07:00:03,041 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: ClosedPoolError("HTTPSConnectionPool(host='10.16.0.1', port=443): Pool is closed.",)
2024-11-05 07:00:04,042 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-05 07:00:05,071 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: ClosedPoolError("HTTPSConnectionPool(host='10.16.0.1', port=443): Pool is closed.",)
2024-11-05 07:00:06,072 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-05 07:00:06,547 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: ClosedPoolError("HTTPSConnectionPool(host='10.16.0.1', port=443): Pool is closed.",)
2024-11-05 07:00:07,548 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-05 07:00:08,578 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: ClosedPoolError("HTTPSConnectionPool(host='10.16.0.1', port=443): Pool is closed.",)
2024-11-05 07:00:09,578 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-05 07:00:10,051 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: ClosedPoolError("HTTPSConnectionPool(host='10.16.0.1', port=443): Pool is closed.",)
2024-11-05 07:00:11,052 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-05 07:00:12,082 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: ClosedPoolError("HTTPSConnectionPool(host='10.16.0.1', port=443): Pool is closed.",)
2024-11-05 07:00:13,084 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-05 07:00:13,558 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: ClosedPoolError("HTTPSConnectionPool(host='10.16.0.1', port=443): Pool is closed.",)
2024-11-05 07:00:14,559 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-05 07:00:15,588 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: ClosedPoolError("HTTPSConnectionPool(host='10.16.0.1', port=443): Pool is closed.",)
2024-11-05 07:00:16,075 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: ClosedPoolError("HTTPSConnectionPool(host='10.16.0.1', port=443): Pool is closed.",)
2024-11-05 07:00:16,550 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError('HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ReadTimeoutError("HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Read timed out. (read timeout=2.5)",))',)
2024-11-05 07:00:16,589 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-05 07:00:17,076 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-05 07:00:21,598 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError('HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ReadTimeoutError("HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Read timed out. (read timeout=2.5)",))',)
2024-11-05 07:00:22,085 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError('HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ReadTimeoutError("HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Read timed out. (read timeout=2.5)",))',)
2024-11-05 07:00:22,600 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-05 07:00:23,086 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-05 07:00:24,563 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError("HTTPSConnectionPool(host='10.16.0.1', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')))",)
2024-11-05 07:00:25,565 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-05 07:00:25,590 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: ClosedPoolError("HTTPSConnectionPool(host='10.16.0.1', port=443): Pool is closed.",)
2024-11-05 07:00:26,592 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-05 07:00:28,070 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: ClosedPoolError("HTTPSConnectionPool(host='10.16.0.1', port=443): Pool is closed.",)
2024-11-05 07:00:29,072 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-05 07:00:29,098 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: ClosedPoolError("HTTPSConnectionPool(host='10.16.0.1', port=443): Pool is closed.",)
2024-11-05 07:00:30,099 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)

 * The logs above show up to 50 of the most recent errors * 

--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------

=== Looking at patronictl list info for the cray-spire-postgres cluster with leader pod: cray-spire-postgres-1 ===

--- patronictl, version , list for spire leader pod cray-spire-postgres-1 ---
+ Cluster: cray-spire-postgres (7429654005986693194) ----+----+-----------+
| Member                | Host       | Role    | State   | TL | Lag in MB |
+-----------------------+------------+---------+---------+----+-----------+
| cray-spire-postgres-0 | 10.41.0.36 | Replica | running |  6 |         0 |
| cray-spire-postgres-1 | 10.34.0.46 | Leader  | running |  6 |           |
| cray-spire-postgres-2 | 10.44.0.17 | Replica | running |  6 |        32 |
+-----------------------+------------+---------+---------+----+-----------+
--- WARNING --- cray-spire-postgres members have Lag

NAMESPACE            NAME                                                              READY   STATUS        RESTARTS        AGE     IP            NODE       NOMINATED NODE   READINESS GATES
spire                cray-spire-postgres-0                                             3/3     Running       0               4d12h   10.41.0.36    ncn-w004   <none>           <none>
spire                cray-spire-postgres-1                                             3/3     Running       0               21h     10.34.0.46    ncn-w002   <none>           <none>
spire                cray-spire-postgres-2                                             3/3     Terminating   0               4d12h   10.44.0.17    ncn-w003   <none>           <none>
spire                cray-spire-postgres-pooler-5997f6f6f5-jkdwx                       2/2     Running       0               28h     10.36.0.64    ncn-w001   <none>           <none>
spire                cray-spire-postgres-pooler-5997f6f6f5-lkxmw                       2/2     Running       0               21h     10.34.0.29    ncn-w002   <none>           <none>
spire                cray-spire-postgres-pooler-5997f6f6f5-q59zj                       2/2     Running       0               4d15h   10.41.0.17    ncn-w004   <none>           <none>
--- ERROR --- not all cray-spire-postgres pods have status 'Running'

--- Error Logs for spire "Leader Pod" cray-spire-postgres-1 --- 
2024-11-06 12:38:20,595 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError('HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ReadTimeoutError("HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Read timed out. (read timeout=2.5)",))',)
2024-11-06 12:38:25,606 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError('HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ReadTimeoutError("HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Read timed out. (read timeout=2.5)",))',)
2024-11-06 12:38:25,611 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError('HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ReadTimeoutError("HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Read timed out. (read timeout=2.5)",))',)
2024-11-06 12:38:25,612 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError('HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ReadTimeoutError("HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Read timed out. (read timeout=2.5)",))',)
2024-11-06 12:38:26,608 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-06 12:38:26,612 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
ERROR:  extension "pg_cron" does not exist
ERROR:  extension "pg_cron" must be installed in schema "pg_catalog"
ERROR:  schema "cron" does not exist

--- Error Logs for spire non-leader pod cray-spire-postgres-0 --- 
2024-11-07 05:10:43,249 ERROR: Request to server https://10.16.0.1:443 failed: ReadTimeoutError("HTTPSConnectionPool(host='10.16.0.1', port=443): Read timed out. (read timeout=4.999696874991059)",)
2024-11-07 05:10:45,891 ERROR: Request to server https://10.16.0.1:443 failed: ReadTimeoutError("HTTPSConnectionPool(host='10.16.0.1', port=443): Read timed out. (read timeout=2.3485216289991513)",)
2024-11-07 05:10:48,248 ERROR: Request to server https://10.16.0.1:443 failed: ReadTimeoutError("HTTPSConnectionPool(host='10.16.0.1', port=443): Read timed out. (read timeout=1.7641767045715824)",)
2024-11-07 05:10:48,249 ERROR: failed to update leader lock
2024-11-07 05:10:55,878 ERROR: Request to server https://10.16.0.1:443 failed: ReadTimeoutError("HTTPSConnectionPool(host='10.16.0.1', port=443): Read timed out. (read timeout=4.986284850980155)",)
2024-11-07 05:10:58,589 ERROR: Request to server https://10.16.0.1:443 failed: ReadTimeoutError("HTTPSConnectionPool(host='10.16.0.1', port=443): Read timed out. (read timeout=2.279023799812421)",)
2024-11-07 05:11:00,023 ERROR: Request to server https://10.16.0.1:443 failed: ReadTimeoutError("HTTPSConnectionPool(host='10.16.0.1', port=443): Read timed out. (read timeout=1)",)
2024-11-07 05:11:00,405 ERROR: Failed to drop replication slot 'cray_spire_postgres_2'
2024-11-07 05:11:00,706 ERROR: Failed to drop replication slot 'cray_spire_postgres_2'
2024-11-07 05:11:10,800 ERROR: Failed to drop replication slot 'cray_spire_postgres_2'
ERROR:  extension "pg_cron" does not exist
ERROR:  extension "pg_cron" must be installed in schema "pg_catalog"
ERROR:  schema "cron" does not exist

--- Error Logs for spire non-leader pod cray-spire-postgres-2 --- 

 * The logs above show up to 50 of the most recent errors * 

--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------

=== Looking at patronictl list info for the spire-postgres cluster with leader pod: spire-postgres-0 ===

--- patronictl, version , list for spire leader pod spire-postgres-0 ---
+ Cluster: spire-postgres (7429654033559437386) ----+----+-----------+
| Member           | Host       | Role    | State   | TL | Lag in MB |
+------------------+------------+---------+---------+----+-----------+
| spire-postgres-0 | 10.41.0.27 | Leader  | running |  5 |           |
| spire-postgres-1 | 10.44.0.13 | Replica | running |  5 |        16 |
| spire-postgres-2 | 10.36.0.71 | Replica | running |  5 |         0 |
+------------------+------------+---------+---------+----+-----------+
--- WARNING --- spire-postgres members have Lag

NAMESPACE            NAME                                                              READY   STATUS        RESTARTS        AGE     IP            NODE       NOMINATED NODE   READINESS GATES
spire                spire-postgres-0                                                  3/3     Running       0               4d12h   10.41.0.27    ncn-w004   <none>           <none>
spire                spire-postgres-1                                                  3/3     Terminating   0               4d12h   10.44.0.13    ncn-w003   <none>           <none>
spire                spire-postgres-2                                                  3/3     Running       0               21h     10.36.0.71    ncn-w001   <none>           <none>
spire                spire-postgres-pooler-6c97d87dd5-7z9nh                            2/2     Running       0               4d15h   10.41.0.18    ncn-w004   <none>           <none>
spire                spire-postgres-pooler-6c97d87dd5-h6b8k                            2/2     Running       0               28h     10.36.0.36    ncn-w001   <none>           <none>
spire                spire-postgres-pooler-6c97d87dd5-n5fzp                            2/2     Running       0               27m     10.34.0.52    ncn-w002   <none>           <none>
spire                spire-postgres-pooler-6c97d87dd5-nt7xb                            2/2     Terminating   0               4d16h   10.44.0.25    ncn-w003   <none>           <none>
--- ERROR --- not all spire-postgres pods have status 'Running'

--- Error Logs for spire "Leader Pod" spire-postgres-0 --- 
2024-11-07 05:10:46,545 ERROR: Request to server https://10.16.0.1:443 failed: ReadTimeoutError("HTTPSConnectionPool(host='10.16.0.1', port=443): Read timed out. (read timeout=4.999681797984522)",)
2024-11-07 05:10:49,452 ERROR: Request to server https://10.16.0.1:443 failed: ReadTimeoutError("HTTPSConnectionPool(host='10.16.0.1', port=443): Read timed out. (read timeout=2.083711222570855)",)
2024-11-07 05:10:51,545 ERROR: Request to server https://10.16.0.1:443 failed: ReadTimeoutError("HTTPSConnectionPool(host='10.16.0.1', port=443): Read timed out. (read timeout=1.7304248337750323)",)
2024-11-07 05:10:51,545 ERROR: failed to update leader lock
ERROR:  extension "pg_cron" does not exist
ERROR:  extension "pg_cron" must be installed in schema "pg_catalog"
ERROR:  schema "cron" does not exist

--- Error Logs for spire non-leader pod spire-postgres-1 --- 

--- Error Logs for spire non-leader pod spire-postgres-2 --- 

 * The logs above show up to 50 of the most recent errors * 

--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------

=== kubectl get pods -A -o wide | grep "NAME\|postgres-" | grep -v "operator\|Completed\|pooler" ===

NAMESPACE            NAME                                                              READY   STATUS        RESTARTS        AGE     IP            NODE       NOMINATED NODE   READINESS GATES
argo                 cray-nls-postgres-0                                               3/3     Running       0               2d3h    10.36.0.17    ncn-w001   <none>           <none>
argo                 cray-nls-postgres-1                                               3/3     Running       0               21h     10.34.0.44    ncn-w002   <none>           <none>
argo                 cray-nls-postgres-2                                               3/3     Running       0               4d12h   10.41.0.75    ncn-w004   <none>           <none>
services             cfs-ara-postgres-0                                                3/3     Running       0               4d12h   10.41.0.70    ncn-w004   <none>           <none>
services             cfs-ara-postgres-1                                                3/3     Terminating   0               4d12h   10.44.0.19    ncn-w003   <none>           <none>
services             cfs-ara-postgres-2                                                3/3     Running       0               21h     10.36.0.73    ncn-w001   <none>           <none>
services             cray-console-data-postgres-0                                      3/3     Running       0               4d13h   10.41.0.37    ncn-w004   <none>           <none>
services             cray-console-data-postgres-1                                      3/3     Running       0               21h     10.34.0.49    ncn-w002   <none>           <none>
services             cray-console-data-postgres-2                                      3/3     Running       0               2d3h    10.36.0.19    ncn-w001   <none>           <none>
services             cray-dhcp-kea-postgres-0                                          3/3     Running       0               21h     10.34.0.48    ncn-w002   <none>           <none>
services             cray-dhcp-kea-postgres-1                                          3/3     Running       0               4d12h   10.41.0.72    ncn-w004   <none>           <none>
services             cray-dhcp-kea-postgres-2                                          3/3     Running       0               47h     10.36.0.30    ncn-w001   <none>           <none>
services             cray-dns-powerdns-postgres-0                                      3/3     Running       0               4d13h   10.41.0.22    ncn-w004   <none>           <none>
services             cray-dns-powerdns-postgres-1                                      3/3     Running       0               21h     10.36.0.28    ncn-w001   <none>           <none>
services             cray-dns-powerdns-postgres-2                                      3/3     Terminating   0               4d12h   10.44.0.68    ncn-w003   <none>           <none>
services             cray-sls-postgres-0                                               3/3     Running       0               4d12h   10.41.0.71    ncn-w004   <none>           <none>
services             cray-sls-postgres-1                                               3/3     Running       0               21h     10.36.0.72    ncn-w001   <none>           <none>
services             cray-sls-postgres-2                                               3/3     Terminating   0               4d12h   10.44.0.67    ncn-w003   <none>           <none>
services             cray-smd-postgres-0                                               3/3     Running       0               21h     10.34.0.47    ncn-w002   <none>           <none>
services             cray-smd-postgres-1                                               3/3     Running       0               2d3h    10.36.0.23    ncn-w001   <none>           <none>
services             cray-smd-postgres-2                                               3/3     Running       0               4d13h   10.41.0.73    ncn-w004   <none>           <none>
services             gitea-vcs-postgres-0                                              3/3     Running       0               4d12h   10.41.0.69    ncn-w004   <none>           <none>
services             gitea-vcs-postgres-1                                              3/3     Running       0               2d3h    10.36.0.14    ncn-w001   <none>           <none>
services             gitea-vcs-postgres-2                                              3/3     Terminating   0               21h     10.44.0.70    ncn-w003   <none>           <none>
services             keycloak-postgres-0                                               3/3     Terminating   0               21h     10.44.0.69    ncn-w003   <none>           <none>
services             keycloak-postgres-1                                               3/3     Running       0               2d3h    10.36.0.18    ncn-w001   <none>           <none>
services             keycloak-postgres-2                                               3/3     Running       0               4d13h   10.41.0.74    ncn-w004   <none>           <none>
spire                cray-spire-postgres-0                                             3/3     Running       0               4d12h   10.41.0.36    ncn-w004   <none>           <none>
spire                cray-spire-postgres-1                                             3/3     Running       0               21h     10.34.0.46    ncn-w002   <none>           <none>
spire                cray-spire-postgres-2                                             3/3     Terminating   0               4d12h   10.44.0.17    ncn-w003   <none>           <none>
spire                spire-postgres-0                                                  3/3     Running       0               4d12h   10.41.0.27    ncn-w004   <none>           <none>
spire                spire-postgres-1                                                  3/3     Terminating   0               4d12h   10.44.0.13    ncn-w003   <none>           <none>
spire                spire-postgres-2                                                  3/3     Running       0               21h     10.36.0.71    ncn-w001   <none>           <none>

--- FAILURE --- 
 
- Errors and Warnings are printed below - 
ERROR: not all cfs-ara-postgres pods have status 'Running'
ERROR: not all cray-dns-powerdns-postgres pods have status 'Running'
ERROR: not all cray-sls-postgres pods have status 'Running'
WARNING: gitea-vcs-postgres members have Lag. Lag does not always indicate there is a problem. Look below to see if prometheus alerts for this are firing.
ERROR: not all gitea-vcs-postgres pods have status 'Running'
ERROR: not all keycloak-postgres pods have status 'Running'
WARNING: cray-spire-postgres members have Lag. Lag does not always indicate there is a problem. Look below to see if prometheus alerts for this are firing.
ERROR: not all cray-spire-postgres pods have status 'Running'
WARNING: spire-postgres members have Lag. Lag does not always indicate there is a problem. Look below to see if prometheus alerts for this are firing.
ERROR: not all spire-postgres pods have status 'Running'

**** Due to Lag being detected, Prometheus alerts will be checked to see if any Postgres Lag alerts are firing ****
 -- Analysis of output is needed to determine if lag is causing a problem --
 -- If nothing is printed below the alert title, then the Lag is likely not causing issues --

** Alert: PostgresqlReplicationLagSMA **

** Alert: PostgresqlReplicationLagServices **

** Alert: PostgresqlFollowerReplicationLagSMA **

** Alert: PostgresqlFollowerReplicationLagServices **
