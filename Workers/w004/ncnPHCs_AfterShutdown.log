             +++++ NCN Postgres Health Checks +++++
=== Can Be Executed on any ncn worker or master node. ===
=== Executing on ncn-m001, Mon Nov 11 13:08:27 UTC 2024 ===

=== Postgresql Operator Version ===
artifactory.algol60.net/csm-docker/stable/registry.opensource.zalan.do/acid/postgres-operator:v1.8.2

=== List of Postgresql Clusters Using Operator ===
NAMESPACE   NAME                         TEAM                VERSION   PODS   VOLUME   CPU-REQUEST   MEMORY-REQUEST   AGE   STATUS
argo        cray-nls-postgres            cray-nls            14        3      2Gi                                     17d   Running
services    cfs-ara-postgres             cfs-ara             14        3      50Gi                                    17d   Running
services    cray-console-data-postgres   cray-console-data   14        3      2Gi                                     17d   Running
services    cray-dhcp-kea-postgres       cray-dhcp-kea       14        3      10Gi     2             1Gi              17d   Running
services    cray-dns-powerdns-postgres   cray-dns-powerdns   14        3      10Gi                                    17d   Running
services    cray-sls-postgres            cray-sls            14        3      1Gi                                     17d   Running
services    cray-smd-postgres            cray-smd            14        3      100Gi    4             8Gi              17d   Running
services    gitea-vcs-postgres           gitea-vcs           14        3      50Gi                                    17d   Running
services    keycloak-postgres            keycloak            14        3      10Gi                                    17d   Running
spire       cray-spire-postgres          cray-spire          14        3      60Gi     4             4Gi              17d   Running
spire       spire-postgres               spire               14        3      60Gi     4             4Gi              17d   Running

=== Look at patronictl list info for each cluster, determine and attach to leader of each cluster ===
=== Report status of postgres pods in cluster ===
-----------------------------------------------------------------------------------------------------

=== Looking at patronictl list info for the cray-nls-postgres cluster with leader pod: cray-nls-postgres-0 ===

--- patronictl, version , list for argo leader pod cray-nls-postgres-0 ---
+ Cluster: cray-nls-postgres (7429648723677089861) ----+----+-----------+
| Member              | Host       | Role    | State   | TL | Lag in MB |
+---------------------+------------+---------+---------+----+-----------+
| cray-nls-postgres-0 | 10.36.0.17 | Leader  | running |  6 |           |
| cray-nls-postgres-1 | 10.34.0.44 | Replica | running |  6 |         0 |
| cray-nls-postgres-2 | 10.41.0.75 | Replica | running |  6 |         0 |
+---------------------+------------+---------+---------+----+-----------+
NAMESPACE            NAME                                                              READY   STATUS        RESTARTS        AGE     IP            NODE       NOMINATED NODE   READINESS GATES
argo                 cray-nls-postgres-0                                               3/3     Running       0               6d6h    10.36.0.17    ncn-w001   <none>           <none>
argo                 cray-nls-postgres-1                                               3/3     Running       0               5d      10.34.0.44    ncn-w002   <none>           <none>
argo                 cray-nls-postgres-2                                               3/3     Terminating   0               8d      10.41.0.75    ncn-w004   <none>           <none>
--- ERROR --- not all cray-nls-postgres pods have status 'Running'

--- Error Logs for argo "Leader Pod" cray-nls-postgres-0 --- 
ERROR:  extension "pg_cron" does not exist
ERROR:  extension "pg_cron" must be installed in schema "pg_catalog"
ERROR:  schema "cron" does not exist

--- Error Logs for argo non-leader pod cray-nls-postgres-1 --- 
2024-11-06 12:38:20,976 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError('HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ReadTimeoutError("HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Read timed out. (read timeout=2.5)",))',)
2024-11-06 12:38:25,972 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError("HTTPSConnectionPool(host='10.16.0.1', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')))",)
2024-11-06 12:38:25,991 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError('HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ReadTimeoutError("HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Read timed out. (read timeout=2.5)",))',)
2024-11-06 12:38:25,993 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError('HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ReadTimeoutError("HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Read timed out. (read timeout=2.5)",))',)
2024-11-06 12:38:26,973 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-06 12:38:26,992 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-06 12:38:30,979 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError("HTTPSConnectionPool(host='10.16.0.1', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')))",)
2024-11-06 12:38:31,981 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-06 12:38:32,002 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError('HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ReadTimeoutError("HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Read timed out. (read timeout=2.5)",))',)
2024-11-06 12:38:33,003 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-06 12:38:33,488 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: ClosedPoolError("HTTPSConnectionPool(host='10.16.0.1', port=443): Pool is closed.",)
2024-11-06 12:38:34,489 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-06 12:38:36,997 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError("HTTPSConnectionPool(host='10.16.0.1', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ProtocolError('Connection aborted.', OSError(0, 'Error')))",)
2024-11-06 12:38:37,998 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)

--- Error Logs for argo non-leader pod cray-nls-postgres-2 --- 

 * The logs above show up to 50 of the most recent errors * 

--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------

=== Looking at patronictl list info for the cfs-ara-postgres cluster with leader pod: cfs-ara-postgres-2 ===

--- patronictl, version , list for services leader pod cfs-ara-postgres-2 ---
+ Cluster: cfs-ara-postgres (7429653337307897930) ----+----+-----------+
| Member             | Host       | Role    | State   | TL | Lag in MB |
+--------------------+------------+---------+---------+----+-----------+
| cfs-ara-postgres-0 | 10.41.0.70 | Replica | running |  5 |        16 |
| cfs-ara-postgres-1 | 10.46.0.15 | Replica | running |  6 |         0 |
| cfs-ara-postgres-2 | 10.36.0.73 | Leader  | running |  6 |           |
+--------------------+------------+---------+---------+----+-----------+
--- WARNING --- cfs-ara-postgres members have Lag

NAMESPACE            NAME                                                              READY   STATUS        RESTARTS        AGE     IP            NODE       NOMINATED NODE   READINESS GATES
services             cfs-ara-postgres-0                                                3/3     Terminating   0               8d      10.41.0.70    ncn-w004   <none>           <none>
services             cfs-ara-postgres-1                                                3/3     Running       0               4d2h    10.46.0.15    ncn-w005   <none>           <none>
services             cfs-ara-postgres-2                                                3/3     Running       0               5d      10.36.0.73    ncn-w001   <none>           <none>
--- ERROR --- not all cfs-ara-postgres pods have status 'Running'

--- Error Logs for services "Leader Pod" cfs-ara-postgres-2 --- 
ERROR:  extension "pg_cron" does not exist
ERROR:  extension "pg_cron" must be installed in schema "pg_catalog"
ERROR:  schema "cron" does not exist

--- Error Logs for services non-leader pod cfs-ara-postgres-0 --- 

--- Error Logs for services non-leader pod cfs-ara-postgres-1 --- 

 * The logs above show up to 50 of the most recent errors * 

--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------

=== Looking at patronictl list info for the cray-console-data-postgres cluster with leader pod: cray-console-data-postgres-2 ===

--- patronictl, version , list for services leader pod cray-console-data-postgres-2 ---
+ Cluster: cray-console-data-postgres (7429653366548672586) ----+----+-----------+
| Member                       | Host       | Role    | State   | TL | Lag in MB |
+------------------------------+------------+---------+---------+----+-----------+
| cray-console-data-postgres-0 | 10.41.0.37 | Replica | running |  3 |        32 |
| cray-console-data-postgres-1 | 10.34.0.49 | Replica | running |  4 |         0 |
| cray-console-data-postgres-2 | 10.36.0.19 | Leader  | running |  4 |           |
+------------------------------+------------+---------+---------+----+-----------+
--- WARNING --- cray-console-data-postgres members have Lag

NAMESPACE            NAME                                                              READY   STATUS            RESTARTS        AGE     IP            NODE       NOMINATED NODE   READINESS GATES
services             cray-console-data-postgres-0                                      3/3     Terminating       0               8d      10.41.0.37    ncn-w004   <none>           <none>
services             cray-console-data-postgres-1                                      3/3     Running           0               5d      10.34.0.49    ncn-w002   <none>           <none>
services             cray-console-data-postgres-2                                      3/3     Running           0               6d6h    10.36.0.19    ncn-w001   <none>           <none>
--- ERROR --- not all cray-console-data-postgres pods have status 'Running'

--- Error Logs for services "Leader Pod" cray-console-data-postgres-2 --- 

--- Error Logs for services non-leader pod cray-console-data-postgres-0 --- 

--- Error Logs for services non-leader pod cray-console-data-postgres-1 --- 
2024-11-06 12:38:31,751 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError('HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ReadTimeoutError("HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Read timed out. (read timeout=2.5)",))',)
2024-11-06 12:38:36,743 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError("HTTPSConnectionPool(host='10.16.0.1', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')))",)
2024-11-06 12:38:36,763 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError('HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ReadTimeoutError("HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Read timed out. (read timeout=2.5)",))',)
2024-11-06 12:38:36,765 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError('HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ReadTimeoutError("HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Read timed out. (read timeout=2.5)",))',)
2024-11-06 12:38:37,745 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-06 12:38:37,764 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)

 * The logs above show up to 50 of the most recent errors * 

--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------

=== Looking at patronictl list info for the cray-dhcp-kea-postgres cluster with leader pod: cray-dhcp-kea-postgres-0 ===

--- patronictl, version , list for services leader pod cray-dhcp-kea-postgres-0 ---
+ Cluster: cray-dhcp-kea-postgres (7429648994707337289) ----+----+-----------+
| Member                   | Host       | Role    | State   | TL | Lag in MB |
+--------------------------+------------+---------+---------+----+-----------+
| cray-dhcp-kea-postgres-0 | 10.34.0.48 | Leader  | running |  6 |           |
| cray-dhcp-kea-postgres-1 | 10.41.0.72 | Replica | running |  5 |        32 |
| cray-dhcp-kea-postgres-2 | 10.36.0.30 | Replica | running |  6 |         0 |
+--------------------------+------------+---------+---------+----+-----------+
--- WARNING --- cray-dhcp-kea-postgres members have Lag

NAMESPACE            NAME                                                              READY   STATUS        RESTARTS        AGE     IP            NODE       NOMINATED NODE   READINESS GATES
services             cray-dhcp-kea-postgres-0                                          3/3     Running       0               5d      10.34.0.48    ncn-w002   <none>           <none>
services             cray-dhcp-kea-postgres-1                                          3/3     Terminating   0               8d      10.41.0.72    ncn-w004   <none>           <none>
services             cray-dhcp-kea-postgres-2                                          3/3     Running       0               6d2h    10.36.0.30    ncn-w001   <none>           <none>
--- ERROR --- not all cray-dhcp-kea-postgres pods have status 'Running'

--- Error Logs for services "Leader Pod" cray-dhcp-kea-postgres-0 --- 
2024-11-06 12:38:31,907 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError('HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ReadTimeoutError("HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Read timed out. (read timeout=2.5)",))',)
2024-11-06 12:38:36,899 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError("HTTPSConnectionPool(host='10.16.0.1', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')))",)
2024-11-06 12:38:36,921 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError('HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ReadTimeoutError("HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Read timed out. (read timeout=2.5)",))',)
2024-11-06 12:38:36,923 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError('HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ReadTimeoutError("HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Read timed out. (read timeout=2.5)",))',)
2024-11-06 12:38:37,901 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-06 12:38:37,924 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
ERROR:  extension "pg_cron" does not exist
ERROR:  extension "pg_cron" must be installed in schema "pg_catalog"
ERROR:  schema "cron" does not exist

--- Error Logs for services non-leader pod cray-dhcp-kea-postgres-1 --- 

--- Error Logs for services non-leader pod cray-dhcp-kea-postgres-2 --- 

 * The logs above show up to 50 of the most recent errors * 

--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------

=== Looking at patronictl list info for the cray-dns-powerdns-postgres cluster with leader pod: cray-dns-powerdns-postgres-2 ===

--- patronictl, version , list for services leader pod cray-dns-powerdns-postgres-2 ---
+ Cluster: cray-dns-powerdns-postgres (7429649497407156297) ----+----+-----------+
| Member                       | Host       | Role    | State   | TL | Lag in MB |
+------------------------------+------------+---------+---------+----+-----------+
| cray-dns-powerdns-postgres-0 | 10.41.0.22 | Replica | running |  3 |        16 |
| cray-dns-powerdns-postgres-1 | 10.36.0.28 | Replica | running |  4 |         0 |
| cray-dns-powerdns-postgres-2 | 10.46.0.27 | Leader  | running |  4 |           |
+------------------------------+------------+---------+---------+----+-----------+
--- WARNING --- cray-dns-powerdns-postgres members have Lag

NAMESPACE            NAME                                                              READY   STATUS        RESTARTS        AGE     IP            NODE       NOMINATED NODE   READINESS GATES
services             cray-dns-powerdns-postgres-0                                      3/3     Terminating   0               8d      10.41.0.22    ncn-w004   <none>           <none>
services             cray-dns-powerdns-postgres-1                                      3/3     Running       0               5d      10.36.0.28    ncn-w001   <none>           <none>
services             cray-dns-powerdns-postgres-2                                      3/3     Running       0               4d2h    10.46.0.27    ncn-w005   <none>           <none>
--- ERROR --- not all cray-dns-powerdns-postgres pods have status 'Running'

--- Error Logs for services "Leader Pod" cray-dns-powerdns-postgres-2 --- 
ERROR:  extension "pg_cron" does not exist
ERROR:  extension "pg_cron" must be installed in schema "pg_catalog"
ERROR:  schema "cron" does not exist

--- Error Logs for services non-leader pod cray-dns-powerdns-postgres-0 --- 

--- Error Logs for services non-leader pod cray-dns-powerdns-postgres-1 --- 

 * The logs above show up to 50 of the most recent errors * 

--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------

=== Looking at patronictl list info for the cray-sls-postgres cluster with leader pod: cray-sls-postgres-2 ===

--- patronictl, version , list for services leader pod cray-sls-postgres-2 ---
+ Cluster: cray-sls-postgres (7429648913392148553) ----+----+-----------+
| Member              | Host       | Role    | State   | TL | Lag in MB |
+---------------------+------------+---------+---------+----+-----------+
| cray-sls-postgres-0 | 10.41.0.71 | Replica | running |  6 |        16 |
| cray-sls-postgres-1 | 10.36.0.72 | Replica | running |  7 |         0 |
| cray-sls-postgres-2 | 10.46.0.17 | Leader  | running |  7 |           |
+---------------------+------------+---------+---------+----+-----------+
--- WARNING --- cray-sls-postgres members have Lag

NAMESPACE            NAME                                                              READY   STATUS        RESTARTS        AGE     IP            NODE       NOMINATED NODE   READINESS GATES
services             cray-sls-postgres-0                                               3/3     Terminating   0               8d      10.41.0.71    ncn-w004   <none>           <none>
services             cray-sls-postgres-1                                               3/3     Running       0               5d      10.36.0.72    ncn-w001   <none>           <none>
services             cray-sls-postgres-2                                               3/3     Running       0               4d2h    10.46.0.17    ncn-w005   <none>           <none>
--- ERROR --- not all cray-sls-postgres pods have status 'Running'

--- Error Logs for services "Leader Pod" cray-sls-postgres-2 --- 
2024-11-07 10:23:44,078 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError('HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ReadTimeoutError("HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Read timed out. (read timeout=2.5)",))',)
2024-11-07 10:23:49,075 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError("HTTPSConnectionPool(host='10.16.0.1', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')))",)
2024-11-07 10:23:49,089 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError('HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ReadTimeoutError("HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Read timed out. (read timeout=2.5)",))',)
2024-11-07 10:23:49,094 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError('HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ReadTimeoutError("HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Read timed out. (read timeout=2.5)",))',)
2024-11-07 10:23:50,076 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-07 10:23:50,091 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-07 10:23:54,086 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError("HTTPSConnectionPool(host='10.16.0.1', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')))",)
2024-11-07 10:23:55,088 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-07 10:23:55,098 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError('HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ReadTimeoutError("HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Read timed out. (read timeout=2.5)",))',)
2024-11-07 10:23:56,099 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-07 10:23:57,594 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: ClosedPoolError("HTTPSConnectionPool(host='10.16.0.1', port=443): Pool is closed.",)
2024-11-07 10:23:58,595 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-07 10:23:58,603 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: ClosedPoolError("HTTPSConnectionPool(host='10.16.0.1', port=443): Pool is closed.",)
2024-11-07 10:23:59,604 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-07 10:24:01,101 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: ClosedPoolError("HTTPSConnectionPool(host='10.16.0.1', port=443): Pool is closed.",)
2024-11-07 10:24:01,594 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: ClosedPoolError("HTTPSConnectionPool(host='10.16.0.1', port=443): Pool is closed.",)
2024-11-07 10:24:02,103 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-07 10:24:02,598 ERROR: Request to server https://10.16.0.1:443 failed: ClosedPoolError("HTTPSConnectionPool(host='10.16.0.1', port=443): Pool is closed.",)
2024-11-07 10:24:03,600 ERROR: ObjectCache.run K8sConnectionFailed('No more API server nodes in the cluster',)
ERROR:  extension "pg_cron" does not exist
ERROR:  extension "pg_cron" must be installed in schema "pg_catalog"
ERROR:  schema "cron" does not exist

--- Error Logs for services non-leader pod cray-sls-postgres-0 --- 

--- Error Logs for services non-leader pod cray-sls-postgres-1 --- 

 * The logs above show up to 50 of the most recent errors * 

--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------

=== Looking at patronictl list info for the cray-smd-postgres cluster with leader pod: cray-smd-postgres-1 ===

--- patronictl, version , list for services leader pod cray-smd-postgres-1 ---
+ Cluster: cray-smd-postgres (7429648967686664265) ----+----+-----------+
| Member              | Host       | Role    | State   | TL | Lag in MB |
+---------------------+------------+---------+---------+----+-----------+
| cray-smd-postgres-0 | 10.34.0.47 | Replica | running |  5 |         0 |
| cray-smd-postgres-1 | 10.36.0.23 | Leader  | running |  5 |           |
| cray-smd-postgres-2 | 10.41.0.73 | Replica | running |  4 |        16 |
+---------------------+------------+---------+---------+----+-----------+
--- WARNING --- cray-smd-postgres members have Lag

NAMESPACE            NAME                                                              READY   STATUS        RESTARTS        AGE     IP            NODE       NOMINATED NODE   READINESS GATES
services             cray-smd-postgres-0                                               3/3     Running           0               5d      10.34.0.47    ncn-w002   <none>           <none>
services             cray-smd-postgres-1                                               3/3     Running           0               6d6h    10.36.0.23    ncn-w001   <none>           <none>
services             cray-smd-postgres-2                                               3/3     Terminating       0               8d      10.41.0.73    ncn-w004   <none>           <none>
--- ERROR --- not all cray-smd-postgres pods have status 'Running'

--- Error Logs for services "Leader Pod" cray-smd-postgres-1 --- 
2024-11-05 07:00:06,306 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError('HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ReadTimeoutError("HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Read timed out. (read timeout=2.5)",))',)
2024-11-05 07:00:11,318 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError('HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ReadTimeoutError("HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Read timed out. (read timeout=2.5)",))',)
2024-11-05 07:00:11,321 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError('HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ReadTimeoutError("HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Read timed out. (read timeout=2.5)",))',)
2024-11-05 07:00:11,322 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError('HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ReadTimeoutError("HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Read timed out. (read timeout=2.5)",))',)
2024-11-05 07:00:12,320 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-05 07:00:12,324 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-05 07:00:17,330 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError('HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ReadTimeoutError("HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Read timed out. (read timeout=2.5)",))',)
2024-11-05 07:00:17,332 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError('HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ReadTimeoutError("HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Read timed out. (read timeout=2.5)",))',)
2024-11-05 07:00:18,332 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-05 07:00:18,334 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-05 07:00:23,345 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError('HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ReadTimeoutError("HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Read timed out. (read timeout=2.5)",))',)
2024-11-05 07:00:23,346 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError('HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ReadTimeoutError("HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Read timed out. (read timeout=2.5)",))',)
2024-11-05 07:00:24,346 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-05 07:00:24,347 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
ERROR:  extension "pg_cron" does not exist
ERROR:  extension "pg_cron" must be installed in schema "pg_catalog"
ERROR:  schema "cron" does not exist

--- Error Logs for services non-leader pod cray-smd-postgres-0 --- 

--- Error Logs for services non-leader pod cray-smd-postgres-2 --- 

 * The logs above show up to 50 of the most recent errors * 

--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------

=== Looking at patronictl list info for the gitea-vcs-postgres cluster with leader pod: gitea-vcs-postgres-1 ===

--- patronictl, version , list for services leader pod gitea-vcs-postgres-1 ---
+ Cluster: gitea-vcs-postgres (7429653957876965450) ----+----+-----------+
| Member               | Host       | Role    | State   | TL | Lag in MB |
+----------------------+------------+---------+---------+----+-----------+
| gitea-vcs-postgres-0 | 10.41.0.69 | Replica | running |  4 |        16 |
| gitea-vcs-postgres-1 | 10.36.0.14 | Leader  | running |  5 |           |
| gitea-vcs-postgres-2 | 10.46.0.28 | Replica | running |  5 |         0 |
+----------------------+------------+---------+---------+----+-----------+
--- WARNING --- gitea-vcs-postgres members have Lag

NAMESPACE            NAME                                                              READY   STATUS            RESTARTS        AGE     IP            NODE       NOMINATED NODE   READINESS GATES
services             gitea-vcs-postgres-0                                              3/3     Terminating       0               8d      10.41.0.69    ncn-w004   <none>           <none>
services             gitea-vcs-postgres-1                                              3/3     Running           0               6d6h    10.36.0.14    ncn-w001   <none>           <none>
services             gitea-vcs-postgres-2                                              3/3     Running           0               4d2h    10.46.0.28    ncn-w005   <none>           <none>
--- ERROR --- not all gitea-vcs-postgres pods have status 'Running'

--- Error Logs for services "Leader Pod" gitea-vcs-postgres-1 --- 
ERROR:  extension "pg_cron" does not exist
ERROR:  extension "pg_cron" must be installed in schema "pg_catalog"
ERROR:  schema "cron" does not exist

--- Error Logs for services non-leader pod gitea-vcs-postgres-0 --- 

--- Error Logs for services non-leader pod gitea-vcs-postgres-2 --- 

 * The logs above show up to 50 of the most recent errors * 

--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------

=== Looking at patronictl list info for the keycloak-postgres cluster with leader pod: keycloak-postgres-0 ===

--- patronictl, version , list for services leader pod keycloak-postgres-0 ---
+ Cluster: keycloak-postgres (7429648627273879625) ----+----+-----------+
| Member              | Host       | Role    | State   | TL | Lag in MB |
+---------------------+------------+---------+---------+----+-----------+
| keycloak-postgres-0 | 10.46.0.18 | Leader  | running |  5 |           |
| keycloak-postgres-1 | 10.36.0.18 | Replica | running |  5 |         0 |
| keycloak-postgres-2 | 10.41.0.74 | Replica | running |  4 |        16 |
+---------------------+------------+---------+---------+----+-----------+
--- WARNING --- keycloak-postgres members have Lag

NAMESPACE            NAME                                                              READY   STATUS            RESTARTS        AGE     IP            NODE       NOMINATED NODE   READINESS GATES
services             keycloak-postgres-0                                               3/3     Running           0               4d2h    10.46.0.18    ncn-w005   <none>           <none>
services             keycloak-postgres-1                                               3/3     Running           0               6d6h    10.36.0.18    ncn-w001   <none>           <none>
services             keycloak-postgres-2                                               3/3     Terminating       0               8d      10.41.0.74    ncn-w004   <none>           <none>
--- ERROR --- not all keycloak-postgres pods have status 'Running'

--- Error Logs for services "Leader Pod" keycloak-postgres-0 --- 
2024-11-07 10:23:44,034 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError('HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ReadTimeoutError("HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Read timed out. (read timeout=2.5)",))',)
2024-11-07 10:23:49,026 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError("HTTPSConnectionPool(host='10.16.0.1', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')))",)
2024-11-07 10:23:49,027 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError("HTTPSConnectionPool(host='10.16.0.1', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')))",)
2024-11-07 10:23:49,050 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError('HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ReadTimeoutError("HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Read timed out. (read timeout=2.5)",))',)
2024-11-07 10:23:50,028 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-07 10:23:50,052 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-07 10:23:54,038 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError('HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ReadTimeoutError("HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Read timed out. (read timeout=2.5)",))',)
2024-11-07 10:23:55,038 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError('HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ReadTimeoutError("HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Read timed out. (read timeout=2.5)",))',)
2024-11-07 10:23:55,039 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-07 10:23:56,039 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-07 10:23:56,550 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError("HTTPSConnectionPool(host='10.16.0.1', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')))",)
2024-11-07 10:23:56,551 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: ClosedPoolError("HTTPSConnectionPool(host='10.16.0.1', port=443): Pool is closed.",)
2024-11-07 10:23:57,551 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-07 10:23:57,552 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
ERROR:  extension "pg_cron" does not exist
ERROR:  extension "pg_cron" must be installed in schema "pg_catalog"
ERROR:  schema "cron" does not exist

--- Error Logs for services non-leader pod keycloak-postgres-1 --- 
2024-11-05 06:59:46,034 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-05 06:59:46,036 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-05 06:59:49,017 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError('HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ReadTimeoutError("HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Read timed out. (read timeout=2.5)",))',)
2024-11-05 06:59:50,018 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-05 06:59:51,046 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError('HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ReadTimeoutError("HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Read timed out. (read timeout=2.5)",))',)
2024-11-05 06:59:52,048 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-05 06:59:52,523 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: ClosedPoolError("HTTPSConnectionPool(host='10.16.0.1', port=443): Pool is closed.",)
2024-11-05 06:59:53,524 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-05 06:59:54,553 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: ClosedPoolError("HTTPSConnectionPool(host='10.16.0.1', port=443): Pool is closed.",)
2024-11-05 06:59:55,554 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-05 06:59:56,029 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: ClosedPoolError("HTTPSConnectionPool(host='10.16.0.1', port=443): Pool is closed.",)
2024-11-05 06:59:57,030 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-05 06:59:58,059 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: ClosedPoolError("HTTPSConnectionPool(host='10.16.0.1', port=443): Pool is closed.",)
2024-11-05 06:59:59,060 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-05 06:59:59,535 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: ClosedPoolError("HTTPSConnectionPool(host='10.16.0.1', port=443): Pool is closed.",)
2024-11-05 07:00:00,023 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: ClosedPoolError("HTTPSConnectionPool(host='10.16.0.1', port=443): Pool is closed.",)
2024-11-05 07:00:00,536 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-05 07:00:01,566 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: ClosedPoolError("HTTPSConnectionPool(host='10.16.0.1', port=443): Pool is closed.",)
2024-11-05 07:00:02,566 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-05 07:00:03,041 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: ClosedPoolError("HTTPSConnectionPool(host='10.16.0.1', port=443): Pool is closed.",)
2024-11-05 07:00:04,042 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-05 07:00:05,071 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: ClosedPoolError("HTTPSConnectionPool(host='10.16.0.1', port=443): Pool is closed.",)
2024-11-05 07:00:06,072 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-05 07:00:06,547 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: ClosedPoolError("HTTPSConnectionPool(host='10.16.0.1', port=443): Pool is closed.",)
2024-11-05 07:00:07,548 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-05 07:00:08,578 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: ClosedPoolError("HTTPSConnectionPool(host='10.16.0.1', port=443): Pool is closed.",)
2024-11-05 07:00:09,578 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-05 07:00:10,051 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: ClosedPoolError("HTTPSConnectionPool(host='10.16.0.1', port=443): Pool is closed.",)
2024-11-05 07:00:11,052 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-05 07:00:12,082 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: ClosedPoolError("HTTPSConnectionPool(host='10.16.0.1', port=443): Pool is closed.",)
2024-11-05 07:00:13,084 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-05 07:00:13,558 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: ClosedPoolError("HTTPSConnectionPool(host='10.16.0.1', port=443): Pool is closed.",)
2024-11-05 07:00:14,559 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-05 07:00:15,588 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: ClosedPoolError("HTTPSConnectionPool(host='10.16.0.1', port=443): Pool is closed.",)
2024-11-05 07:00:16,075 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: ClosedPoolError("HTTPSConnectionPool(host='10.16.0.1', port=443): Pool is closed.",)
2024-11-05 07:00:16,550 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError('HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ReadTimeoutError("HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Read timed out. (read timeout=2.5)",))',)
2024-11-05 07:00:16,589 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-05 07:00:17,076 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-05 07:00:21,598 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError('HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ReadTimeoutError("HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Read timed out. (read timeout=2.5)",))',)
2024-11-05 07:00:22,085 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError('HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ReadTimeoutError("HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Read timed out. (read timeout=2.5)",))',)
2024-11-05 07:00:22,600 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-05 07:00:23,086 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-05 07:00:24,563 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError("HTTPSConnectionPool(host='10.16.0.1', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')))",)
2024-11-05 07:00:25,565 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-05 07:00:25,590 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: ClosedPoolError("HTTPSConnectionPool(host='10.16.0.1', port=443): Pool is closed.",)
2024-11-05 07:00:26,592 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-05 07:00:28,070 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: ClosedPoolError("HTTPSConnectionPool(host='10.16.0.1', port=443): Pool is closed.",)
2024-11-05 07:00:29,072 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-05 07:00:29,098 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: ClosedPoolError("HTTPSConnectionPool(host='10.16.0.1', port=443): Pool is closed.",)
2024-11-05 07:00:30,099 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)

--- Error Logs for services non-leader pod keycloak-postgres-2 --- 

 * The logs above show up to 50 of the most recent errors * 

--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------

=== Looking at patronictl list info for the cray-spire-postgres cluster with leader pod: cray-spire-postgres-1 ===

--- patronictl, version , list for spire leader pod cray-spire-postgres-1 ---
+ Cluster: cray-spire-postgres (7429654005986693194) ----+----+-----------+
| Member                | Host       | Role    | State   | TL | Lag in MB |
+-----------------------+------------+---------+---------+----+-----------+
| cray-spire-postgres-0 | 10.41.0.36 | Replica | running |  6 |        32 |
| cray-spire-postgres-1 | 10.34.0.46 | Leader  | running |  6 |           |
| cray-spire-postgres-2 | 10.46.0.21 | Replica | running |  6 |         0 |
+-----------------------+------------+---------+---------+----+-----------+
--- WARNING --- cray-spire-postgres members have Lag

NAMESPACE            NAME                                                              READY   STATUS        RESTARTS        AGE     IP            NODE       NOMINATED NODE   READINESS GATES
spire                cray-spire-postgres-0                                             3/3     Terminating   0               8d      10.41.0.36    ncn-w004   <none>           <none>
spire                cray-spire-postgres-1                                             3/3     Running       0               5d      10.34.0.46    ncn-w002   <none>           <none>
spire                cray-spire-postgres-2                                             3/3     Running       0               4d2h    10.46.0.21    ncn-w005   <none>           <none>
spire                cray-spire-postgres-pooler-5997f6f6f5-dmwl8                       2/2     Running       0               58m     10.46.0.37    ncn-w005   <none>           <none>
spire                cray-spire-postgres-pooler-5997f6f6f5-jkdwx                       2/2     Running       0               5d7h    10.36.0.64    ncn-w001   <none>           <none>
spire                cray-spire-postgres-pooler-5997f6f6f5-lkxmw                       2/2     Running       0               5d      10.34.0.29    ncn-w002   <none>           <none>
spire                cray-spire-postgres-pooler-5997f6f6f5-q59zj                       2/2     Terminating   0               8d      10.41.0.17    ncn-w004   <none>           <none>
--- ERROR --- not all cray-spire-postgres pods have status 'Running'

--- Error Logs for spire "Leader Pod" cray-spire-postgres-1 --- 
2024-11-06 12:38:20,595 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError('HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ReadTimeoutError("HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Read timed out. (read timeout=2.5)",))',)
2024-11-06 12:38:25,606 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError('HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ReadTimeoutError("HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Read timed out. (read timeout=2.5)",))',)
2024-11-06 12:38:25,611 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError('HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ReadTimeoutError("HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Read timed out. (read timeout=2.5)",))',)
2024-11-06 12:38:25,612 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError('HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ReadTimeoutError("HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Read timed out. (read timeout=2.5)",))',)
2024-11-06 12:38:26,608 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-06 12:38:26,612 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
ERROR:  extension "pg_cron" does not exist
ERROR:  extension "pg_cron" must be installed in schema "pg_catalog"
ERROR:  schema "cron" does not exist

--- Error Logs for spire non-leader pod cray-spire-postgres-0 --- 

--- Error Logs for spire non-leader pod cray-spire-postgres-2 --- 
2024-11-07 10:23:53,614 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError('HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ReadTimeoutError("HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Read timed out. (read timeout=2.5)",))',)
2024-11-07 10:23:58,610 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError("HTTPSConnectionPool(host='10.16.0.1', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')))",)
2024-11-07 10:23:58,628 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError('HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ReadTimeoutError("HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Read timed out. (read timeout=2.5)",))',)
2024-11-07 10:23:58,630 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError('HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ReadTimeoutError("HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Read timed out. (read timeout=2.5)",))',)
2024-11-07 10:23:59,612 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-07 10:23:59,629 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)

 * The logs above show up to 50 of the most recent errors * 

--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------

=== Looking at patronictl list info for the spire-postgres cluster with leader pod: spire-postgres-2 ===

--- patronictl, version , list for spire leader pod spire-postgres-2 ---
+ Cluster: spire-postgres (7429654033559437386) ----+----+-----------+
| Member           | Host       | Role    | State   | TL | Lag in MB |
+------------------+------------+---------+---------+----+-----------+
| spire-postgres-0 | 10.41.0.27 | Replica | running |  5 |        32 |
| spire-postgres-1 | 10.44.0.13 | Replica | running |  6 |         0 |
| spire-postgres-2 | 10.36.0.71 | Leader  | running |  6 |           |
+------------------+------------+---------+---------+----+-----------+
--- WARNING --- spire-postgres members have Lag

NAMESPACE            NAME                                                              READY   STATUS            RESTARTS        AGE     IP            NODE       NOMINATED NODE   READINESS GATES
spire                spire-postgres-0                                                  3/3     Terminating       0               8d      10.41.0.27    ncn-w004   <none>           <none>
spire                spire-postgres-1                                                  3/3     Running           0               4d2h    10.44.0.13    ncn-w003   <none>           <none>
spire                spire-postgres-2                                                  3/3     Running           0               5d      10.36.0.71    ncn-w001   <none>           <none>
spire                spire-postgres-pooler-6c97d87dd5-7z9nh                            2/2     Terminating       0               8d      10.41.0.18    ncn-w004   <none>           <none>
spire                spire-postgres-pooler-6c97d87dd5-h6b8k                            2/2     Running           0               5d7h    10.36.0.36    ncn-w001   <none>           <none>
spire                spire-postgres-pooler-6c97d87dd5-n5fzp                            2/2     Running           0               4d3h    10.34.0.52    ncn-w002   <none>           <none>
spire                spire-postgres-pooler-6c97d87dd5-t4r5s                            2/2     Running           0               58m     10.44.0.58    ncn-w003   <none>           <none>
--- ERROR --- not all spire-postgres pods have status 'Running'

--- Error Logs for spire "Leader Pod" spire-postgres-2 --- 
ERROR:  extension "pg_cron" does not exist
ERROR:  extension "pg_cron" must be installed in schema "pg_catalog"
ERROR:  schema "cron" does not exist

--- Error Logs for spire non-leader pod spire-postgres-0 --- 

--- Error Logs for spire non-leader pod spire-postgres-1 --- 
2024-11-07 10:24:00,367 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError('HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ReadTimeoutError("HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Read timed out. (read timeout=2.5)",))',)
2024-11-07 10:24:05,379 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError('HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ReadTimeoutError("HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Read timed out. (read timeout=2.5)",))',)
2024-11-07 10:24:05,383 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError('HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ReadTimeoutError("HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Read timed out. (read timeout=2.5)",))',)
2024-11-07 10:24:05,385 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError('HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ReadTimeoutError("HTTPSConnectionPool(host=\'10.16.0.1\', port=443): Read timed out. (read timeout=2.5)",))',)
2024-11-07 10:24:06,381 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-07 10:24:06,385 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-07 10:24:10,371 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError("HTTPSConnectionPool(host='10.16.0.1', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')))",)
2024-11-07 10:24:10,372 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError("HTTPSConnectionPool(host='10.16.0.1', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer')))",)
2024-11-07 10:24:11,373 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-07 10:24:11,374 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)
2024-11-07 10:24:12,884 ERROR: Failed to get "kubernetes" endpoint from https://10.16.0.1:443: MaxRetryError("HTTPSConnectionPool(host='10.16.0.1', port=443): Max retries exceeded with url: /api/v1/namespaces/default/endpoints/kubernetes (Caused by ProtocolError('Connection aborted.', OSError(0, 'Error')))",)
2024-11-07 10:24:13,885 ERROR: ObjectCache.run K8sException('Could not get the list of K8s API server nodes',)

 * The logs above show up to 50 of the most recent errors * 

--------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------

=== kubectl get pods -A -o wide | grep "NAME\|postgres-" | grep -v "operator\|Completed\|pooler" ===

NAMESPACE            NAME                                                              READY   STATUS            RESTARTS        AGE     IP            NODE       NOMINATED NODE   READINESS GATES
argo                 cray-nls-postgres-0                                               3/3     Running           0               6d6h    10.36.0.17    ncn-w001   <none>           <none>
argo                 cray-nls-postgres-1                                               3/3     Running           0               5d      10.34.0.44    ncn-w002   <none>           <none>
argo                 cray-nls-postgres-2                                               3/3     Terminating       0               8d      10.41.0.75    ncn-w004   <none>           <none>
services             cfs-ara-postgres-0                                                3/3     Terminating       0               8d      10.41.0.70    ncn-w004   <none>           <none>
services             cfs-ara-postgres-1                                                3/3     Running           0               4d2h    10.46.0.15    ncn-w005   <none>           <none>
services             cfs-ara-postgres-2                                                3/3     Running           0               5d      10.36.0.73    ncn-w001   <none>           <none>
services             cray-console-data-postgres-0                                      3/3     Terminating       0               8d      10.41.0.37    ncn-w004   <none>           <none>
services             cray-console-data-postgres-1                                      3/3     Running           0               5d      10.34.0.49    ncn-w002   <none>           <none>
services             cray-console-data-postgres-2                                      3/3     Running           0               6d6h    10.36.0.19    ncn-w001   <none>           <none>
services             cray-dhcp-kea-postgres-0                                          3/3     Running           0               5d      10.34.0.48    ncn-w002   <none>           <none>
services             cray-dhcp-kea-postgres-1                                          3/3     Terminating       0               8d      10.41.0.72    ncn-w004   <none>           <none>
services             cray-dhcp-kea-postgres-2                                          3/3     Running           0               6d2h    10.36.0.30    ncn-w001   <none>           <none>
services             cray-dns-powerdns-postgres-0                                      3/3     Terminating       0               8d      10.41.0.22    ncn-w004   <none>           <none>
services             cray-dns-powerdns-postgres-1                                      3/3     Running           0               5d      10.36.0.28    ncn-w001   <none>           <none>
services             cray-dns-powerdns-postgres-2                                      3/3     Running           0               4d2h    10.46.0.27    ncn-w005   <none>           <none>
services             cray-sls-postgres-0                                               3/3     Terminating       0               8d      10.41.0.71    ncn-w004   <none>           <none>
services             cray-sls-postgres-1                                               3/3     Running           0               5d      10.36.0.72    ncn-w001   <none>           <none>
services             cray-sls-postgres-2                                               3/3     Running           0               4d2h    10.46.0.17    ncn-w005   <none>           <none>
services             cray-smd-postgres-0                                               3/3     Running           0               5d      10.34.0.47    ncn-w002   <none>           <none>
services             cray-smd-postgres-1                                               3/3     Running           0               6d6h    10.36.0.23    ncn-w001   <none>           <none>
services             cray-smd-postgres-2                                               3/3     Terminating       0               8d      10.41.0.73    ncn-w004   <none>           <none>
services             gitea-vcs-postgres-0                                              3/3     Terminating       0               8d      10.41.0.69    ncn-w004   <none>           <none>
services             gitea-vcs-postgres-1                                              3/3     Running           0               6d6h    10.36.0.14    ncn-w001   <none>           <none>
services             gitea-vcs-postgres-2                                              3/3     Running           0               4d2h    10.46.0.28    ncn-w005   <none>           <none>
services             keycloak-postgres-0                                               3/3     Running           0               4d2h    10.46.0.18    ncn-w005   <none>           <none>
services             keycloak-postgres-1                                               3/3     Running           0               6d6h    10.36.0.18    ncn-w001   <none>           <none>
services             keycloak-postgres-2                                               3/3     Terminating       0               8d      10.41.0.74    ncn-w004   <none>           <none>
spire                cray-spire-postgres-0                                             3/3     Terminating       0               8d      10.41.0.36    ncn-w004   <none>           <none>
spire                cray-spire-postgres-1                                             3/3     Running           0               5d      10.34.0.46    ncn-w002   <none>           <none>
spire                cray-spire-postgres-2                                             3/3     Running           0               4d2h    10.46.0.21    ncn-w005   <none>           <none>
spire                spire-postgres-0                                                  3/3     Terminating       0               8d      10.41.0.27    ncn-w004   <none>           <none>
spire                spire-postgres-1                                                  3/3     Running           0               4d2h    10.44.0.13    ncn-w003   <none>           <none>
spire                spire-postgres-2                                                  3/3     Running           0               5d      10.36.0.71    ncn-w001   <none>           <none>

--- FAILURE --- 
 
- Errors and Warnings are printed below - 
ERROR: not all cray-nls-postgres pods have status 'Running'
WARNING: cfs-ara-postgres members have Lag. Lag does not always indicate there is a problem. Look below to see if prometheus alerts for this are firing.
ERROR: not all cfs-ara-postgres pods have status 'Running'
WARNING: cray-console-data-postgres members have Lag. Lag does not always indicate there is a problem. Look below to see if prometheus alerts for this are firing.
ERROR: not all cray-console-data-postgres pods have status 'Running'
WARNING: cray-dhcp-kea-postgres members have Lag. Lag does not always indicate there is a problem. Look below to see if prometheus alerts for this are firing.
ERROR: not all cray-dhcp-kea-postgres pods have status 'Running'
WARNING: cray-dns-powerdns-postgres members have Lag. Lag does not always indicate there is a problem. Look below to see if prometheus alerts for this are firing.
ERROR: not all cray-dns-powerdns-postgres pods have status 'Running'
WARNING: cray-sls-postgres members have Lag. Lag does not always indicate there is a problem. Look below to see if prometheus alerts for this are firing.
ERROR: not all cray-sls-postgres pods have status 'Running'
WARNING: cray-smd-postgres members have Lag. Lag does not always indicate there is a problem. Look below to see if prometheus alerts for this are firing.
ERROR: not all cray-smd-postgres pods have status 'Running'
WARNING: gitea-vcs-postgres members have Lag. Lag does not always indicate there is a problem. Look below to see if prometheus alerts for this are firing.
ERROR: not all gitea-vcs-postgres pods have status 'Running'
WARNING: keycloak-postgres members have Lag. Lag does not always indicate there is a problem. Look below to see if prometheus alerts for this are firing.
ERROR: not all keycloak-postgres pods have status 'Running'
WARNING: cray-spire-postgres members have Lag. Lag does not always indicate there is a problem. Look below to see if prometheus alerts for this are firing.
ERROR: not all cray-spire-postgres pods have status 'Running'
WARNING: spire-postgres members have Lag. Lag does not always indicate there is a problem. Look below to see if prometheus alerts for this are firing.
ERROR: not all spire-postgres pods have status 'Running'

**** Due to Lag being detected, Prometheus alerts will be checked to see if any Postgres Lag alerts are firing ****
 -- Analysis of output is needed to determine if lag is causing a problem --
 -- If nothing is printed below the alert title, then the Lag is likely not causing issues --

** Alert: PostgresqlReplicationLagSMA **

** Alert: PostgresqlReplicationLagServices **

** Alert: PostgresqlFollowerReplicationLagSMA **

** Alert: PostgresqlFollowerReplicationLagServices **
